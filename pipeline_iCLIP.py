"""===========================
Pipeline template
===========================

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

This pipeline computes the word frequencies in the configuration
files :file:``pipeline.ini` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_@template@.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

Pipeline output
===============

.. Describe output files of the pipeline here

Glossary
========

.. glossary::


Code
====

"""
from ruffus import *
import sys
import os
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])


# ---------------------------------------------------
# Specific pipeline tasks
    
''' below, use this to change environment before calling tool/script
need to change env name from py36-v1 to desired one'''
# PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/py36-v1/bin;
# CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/envs/py36-v1;

''' below use command to estimate command computing time and resources'''
#   /usr/bin/time -o %(startfile)s.time -v
  
# Demultiplexing
@follows(mkdir("demultiplexed"))
@split('*.fastq.gz', '*.demux.fastq.gz')
def demux(infile, outfiles):    
    ''' demultiplex and move UMI to end of header using iCount '''
    startfile = " ".join(infile)
    statement = '''  
    PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/iCount/bin;
    CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/envs/iCount;
  
    iCount demultiplex %(startfile)s
    %(adapter)s
    %(demux_barcodes)s
    --out_dir "%(demux_outputdir)s"
    '''
    P.run()


# Cutadapt
@follows(demux)
@follows(mkdir("trimmed"))
@transform('demultiplexed/*NN.fastq.gz', regex(r'demultiplexed/demux_NNN(.*)NN.fastq.gz'), r'trimmed/\1.trim.fastq.gz') 
def cutadapt(infile, outfile):
    ''' trims 3' adapter and removes low quality reads '''
    statement = ''' cutadapt -q %(cutadapt_minphred)s 
    --minimum-length %(cutadapt_minlength)s 
    -a %(general_adapter)s
    -o %(outfile)s %(infile)s
    '''
    P.run()


# STAR remove Reps
@follows(mkdir("mappedreps"))
@transform(cutadapt, regex(r'trimmed/(\S+).trim.fastq.gz'), r'mappedreps/\1.rep.bam')
def STARrmRep(infile, outfile):
    ''' maps to repetitive elements, produces 2 files:
        mapped - name.bam; unmapped name. '''
    outprefix = P.snip(outfile, ".bam")
    job_threads = PARAMS["STARrmRep_threads"]
    statement = '''
    STAR  --runMode alignReads
    --runThreadN %(job_threads)i
    --genomeDir %(STARrmRep_repbase)s
    --limitBAMsortRAM 10000000000
    --readFilesIn %(infile)s
    --outSAMunmapped Within
    --outFilterMultimapNmax 30
    --outFilterMultimapScoreRange 1
    --outFileNamePrefix %(outprefix)s
    --outSAMattributes All
    --readFilesCommand zcat
    --outStd BAM_Unsorted
    --outSAMtype BAM Unsorted
    --outFilterType BySJout
    --outReadsUnmapped Fastx
    --outFilterScoreMin 10
    --alignEndsType EndToEnd
    > %(outfile)s
    '''
    P.run()

# series of commands to fix bam file names to call UMI
@transform(STARrmRep, suffix('.rep.bam'), '.rep.new.bam')
def rep_umifix(infile, outfile):
    statement = ''' samtools view -h -o %(infile)s.sam %(infile)s &&
    cut -f1 %(infile)s.sam | sed 's/\(.*\):/\1_/' >%(infile)s.1.txt &&
    cut -f 2- %(infile)s.sam > %(infile)s.2.txt &&
    paste %(infile)s.1.txt %(infile)s.2.txt > %(infile)s.new.sam &&
    samtools view -h -o %(outfile)s %(infile)s.new.sam '''
    P.run()


#samtools sort
@transform(rep_umifix, suffix('.rep.new.bam'), '.rep.sorted.bam')
def rep_sort(infile, outfile):
    statement = ''' samtools sort %(infile)s -o %(outfile)s
    '''
    P.run()
    
    
# samtools index1
@transform(rep_sort, suffix('.rep.sorted.bam'), '.rep.sorted.bam.bai')
def rep_index(infile, outfile):
    statement = ''' samtools index %(infile)s
    '''
    P.run()


# Deduplicate
@follows(rep_index)
@transform(rep_sort, regex(r'(.*).rep.sorted.bam'), r'\1.rep.dedup.bam')
def rep_dedup(infile,outfile):
    ''' deduplicate samples based on UMI using umi_tools '''
    statement = '''
    umi_tools dedup -I %(infile)s --output-stats=deduplicated -S %(outfile)s
    '''
    P.run()


# Count Reps
@transform(rep_dedup, suffix('.rep.dedup.bam'), '.rep.metrics')
def countRep(infile, outfile):
    '''counts number reads mapping to each repetitive element'''
    statement = '''
    PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/Py2/bin;
    CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/envs/Py2;
    samtools view %(infile)s | 
    /t1-data/user/nsampaio/software/gscripts/gscripts/general/count_aligned_from_sam.py 
    > %(outfile)s
    '''
    P.run()
    
    
## FASTQC
#@follows(STARrmRep)
#@follows(mkdir("fastqc2"))
#@transform('mappedreps/*repUnmapped.out.mate1', regex(r'mappedreps/(.*).repUnmapped.out.mate1'), r'fastqc2/\1.fastqc')
#def fastqc2(infile,outfile):
#    ''' does fastqc on mapped repetitive elements from STARrmRep '''
#    statement = ''' fastqc %(infile)s -o %(general_outputdir)s/fastqc2 > %(outfile)s
#    '''
#    P.run()


# STAR mapping
@follows(STARrmRep)
@follows(mkdir("STARmapped"))
@transform('mappedreps/*repUnmapped.out.mate1', regex(r'mappedreps/(.*).repUnmapped.out.mate1'), r'STARmapped/\1.bam')
def STARmap(infile,outfile):
    ''' maps non-repetitive elements to genome '''
    outprefix = P.snip(outfile, ".bam")
    job_threads = PARAMS["STARmap_threads"]
    statement = '''
    STAR  --runMode alignReads
    --runThreadN %(job_threads)i
    --genomeDir %(STARmap_genome)s
    --readFilesIn %(infile)s
    --outSAMunmapped Within
    --outFilterMultimapNmax 1
    --outFilterMultimapScoreRange 1
    --outFileNamePrefix %(outprefix)s
    --outSAMattributes All
    --outStd BAM_Unsorted
    --outSAMtype BAM Unsorted
    --outFilterType BySJout
    --outReadsUnmapped Fastx
    --outFilterScoreMin 10
    --outSAMattrRGline ID:foo
    --alignEndsType EndToEnd
    > %(outfile)s 
    '''
    P.run()

# series of commands to fix bam file names to call UMI
@transform(STARmap, suffix('.bam'), '.new.bam')
def umifix(infile, outfile):
    statement = ''' samtools view -h -o %(infile)s.sam %(infile)s &&
    cut -f1 %(infile)s.sam | sed 's/\(.*\):/\1_/' >%(infile)s.1.txt &&
    cut -f 2- %(infile)s.sam > %(infile)s.2.txt &&
    paste %(infile)s.1.txt %(infile)s.2.txt > %(infile)s.new.sam &&
    samtools view -h -o %(outfile)s %(infile)s.new.sam '''
    P.run()


#samtools sort
@transform(umifix, suffix('.new.bam'), '.sorted.bam')
def samtools_sort(infile, outfile):
    statement = ''' samtools sort %(infile)s -o %(outfile)s
    '''
    P.run()
    
    
# samtools index1
@follows(samtools_sort)
@transform(samtools_sort, suffix('.sorted.bam'), '.sorted.bam.bai')
def index1(infile, outfile):
    statement = ''' samtools index %(infile)s
    '''
    P.run()


# Deduplicate
@follows(index1)
@transform(samtools_sort, regex(r'(.*).sorted.bam'), r'\1.dedup.bam')
def dedup(infile,outfile):
    ''' deduplicate samples based on UMI using umi_tools '''
    statement = '''
    umi_tools dedup -I %(infile)s --output-stats=deduplicated -S %(outfile)s
    '''
    P.run()


# samtools index2
@transform(dedup, suffix('.dedup.bam'), 'dedup.bam.bai')
def index2(infile, outfile):
    ''' creates index deduplicated bam file, generates .bai '''
    statement = '''samtools index %(infile)s
    '''
    P.run()


## Make bigwig
#@follows(index2)
#@transform(samtools_sort, suffix('.sorted.bam'), '.bw')
#def makeBigWig(infile, outfile):
#    ''' Makes bigwig files for visualization 
#    #### not working because I only have read 1!!!!! '''
#    statement = ''' 
#    PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/Py2/bin
#    CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/envs/Py2
#    /t1-data/user/nsampaio/software/gscripts/gscripts/general/make_bigwig_files.py
#    --bam %(infile)s
#    --genome %(general_chromsize)s
#    --bw_pos %(outfile)
#    '''
#    P.run()
  

## Call peaks
#@follows(index2)
#@transform(dedup, suffix('.sorted.bam'), '.bed')
#def callPeaks(infile, outfile):
#    ''' Calls peaks using CLIPper package'''
#    statement = '''
#    PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/clipper/bin
#    CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/envs/clipper
#    CLIPPER COMMANDS
#    '''
#    P.run() ###### need to get clipper to work and figure out commands
#
#
## Fix scores
#@transform(callPeaks, suffix('.bed'), '.fixed.bed')
#def fixScores(infile, outfile):
#    ''' Fixes p-values to be bed compatible '''
#    statement = ''' 
#    PATH=/t1-data/user/nsampaio/py36-v1/conda-install/envs/Py2/bin
#    CONDA_PREFIX=/t1-data/user/nsampaio/py36-v1/conda-install/Py2/iCount
#    python /t1-data/user/nsampaio/software/gscripts/gscripts/clipseq/fix_scores.py
#    --bed %(infile)s
#    --out_%(outfile)s
#    '''
#    P.run()
#
#
## Bed to BigBed
#@transform(fixScores, suffix('.fixed.bed'), '.fixed.bb')
#def bigBed(infile, outfile):
#    ''' Converts bed file to bigBed file for uploading to the genomeBrowser '''
#    statement = ''' bedToBigBed %(infile)s
#    %(general_chromsize)s
#    %(outfile)s
#    -type=bed6+4
#    '''
#    P.run()
    
@follows(countRep, dedup)
def full():
    pass

   
# ---------------------------------------------------
# Generic pipeline tasks



def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))

